# MyCandyLocal üç¨

Your private, uncensored AI companion.

## Features

- **Local LLM**: Runs completely offline using `llama.cpp` (GGUF models).
- **Hybrid TTS**: 
  - **Speech**: Uses `pyttsx3` for fast, offline speech synthesis.
  - **Sound Effects**: Uses SNAC tokens for non-verbal sounds (moans, laughs, etc.) generated by the LLM.
- **STT**: Whisper-based Speech-to-Text for voice interaction.
- **Visuals**: Generates images and videos (via ComfyUI) on demand.
- **Memory**: Persistent chat history per character.

## Setup

1.  **Install Dependencies**: Ensure Python 3.10+ and Node.js are installed.
2.  **Start**: Run `./start_all.ps1`.
3.  **Access**: Open `http://127.0.0.1:8000/ui` in your browser.

## Usage

-   **Chat**: Type or speak to interact.
-   **Emotes**: Actions in `*asterisks*` are silent (unless they contain sound tokens). Spoken text is read aloud.
-   **Visuals**: Ask for "ein Bild" or "ein Video" to trigger generation.

## Troubleshooting

-   **No Audio?** Check if "Auto-TTS" is enabled in the UI.
-   **Wrong Microphone?** Check your browser settings.
-   **Startup Crash?** Ensure no other python/llama processes are blocking ports.

## Credits

-   Frontend: React + Vite + Tailwind
-   Backend: FastAPI + Python
-   LLM: Llama.cpp
-   TTS: Pyttsx3 + SNAC
