# MyCandyLocal üç¨

Your private, uncensored AI companion.

## Features

- **Local LLM**: Runs completely offline using `llama.cpp` (GGUF models). Currently optimized for **L3-8B-Stheno-v3.2** (High speed/quality).
- **Hybrid TTS**: 
  - **Speech**: Uses `pyttsx3` for fast, offline speech synthesis.
  - **Sound Effects**: Uses SNAC tokens for non-verbal sounds (moans, laughs, etc.) generated by the LLM.
- **Visuals (New! üé®)**: 
  - **Pony Diffusion V6 Support**: Fully optimized ComfyUI workflow (Euler Ancestral, Clip Skip -2, SDXL Resolution).
  - **LoRA Integration**: Supports custom LoRAs (e.g., specific anime characters) via ComfyUI.
  - **Character Consistency**: Define specific "Visual Style" and "Negative Prompts" per character.
  - **Auto-Generation**: LLM autonomously decides when to generate images (`[GENERATE_IMAGE]`).
- **STT**: Whisper-based Speech-to-Text for voice interaction.
- **Memory**: Persistent chat history per character.

## Setup

1.  **Install Dependencies**: Ensure Python 3.10+ and Node.js are installed.
2.  **Start**: Run `./start_all.ps1`.
3.  **Access**: Open `http://127.0.0.1:8000/ui` in your browser.

## Usage

-   **Chat**: Type or speak to interact.
-   **Visuals**: Ask for "ein Bild" or "ein Video" to trigger generation. Or let the AI decide.
-   **Character Edit**: Use the UI to set specific **Positive/Negative Prompts** for your character's look.

## Troubleshooting

-   **Image Artifacts?** Ensure you are using the correct SDXL resolution (default 832x1216).
-   **No Audio?** Check if "Auto-TTS" is enabled in the UI.
-   **Startup Crash?** Run `debug_restart.ps1` to clear stuck processes.

## Credits

-   Frontend: React + Vite + Tailwind
-   Backend: FastAPI + Python
-   LLM: Llama.cpp (Stheno 8B)
-   Image Gen: ComfyUI (Pony V6)
